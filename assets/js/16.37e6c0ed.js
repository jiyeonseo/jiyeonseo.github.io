(window.webpackJsonp=window.webpackJsonp||[]).push([[16],{321:function(a,t,r){a.exports=r.p+"assets/img/spark-The-Structure-Spectrum.45bb4b9e.png"},322:function(a,t,r){a.exports=r.p+"assets/img/spark-data-frame.358d761c.png"},323:function(a,t,r){a.exports=r.p+"assets/img/spark-component.8cfedb7c.png"},324:function(a,t,r){a.exports=r.p+"assets/img/cluster-overview.b3f195aa.png"},325:function(a,t,r){a.exports=r.p+"assets/img/spark-transformation.2fa70935.png"},326:function(a,t,r){a.exports=r.p+"assets/img/spark-action.8185e37d.png"},445:function(a,t,r){"use strict";r.r(t);var e=r(5),s=Object(e.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"cs105x-introduction-to-apache-spark-1편"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#cs105x-introduction-to-apache-spark-1편"}},[a._v("#")]),a._v(" CS105x Introduction to Apache Spark 1편")]),a._v(" "),t("p",[a._v("MOOC 사이트인 edx의 Spark 수업을 들으면서 정리하는 내용입니다.\n부족한 내용 계속 업데이트해 나갈 예정입니다 😃 혹시 부족한 내용 혹은 틀린 부분이 있다면 언제든 알려주세요!")]),a._v(" "),t("p",[a._v("강의는 "),t("a",{attrs:{href:"https://courses.edx.org/courses/course-v1:BerkeleyX+CS105x+1T2016/info",target:"_blank",rel:"noopener noreferrer"}},[a._v("CS105x Introduction to Apache Spark"),t("OutboundLink")],1),a._v("\n이며 언어는 Python 2.7 입니다.")]),a._v(" "),t("h2",{attrs:{id:"apache-spark란"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#apache-spark란"}},[a._v("#")]),a._v(" "),t("a",{attrs:{href:"http://spark.apache.org/",target:"_blank",rel:"noopener noreferrer"}},[a._v("Apache Spark"),t("OutboundLink")],1),a._v("란?")]),a._v(" "),t("ul",[t("li",[a._v("Scalable, efficient analysis of Big Data")]),a._v(" "),t("li",[a._v("빅 데이터를 위한 확장 가능한 효과적인 분석 툴")])]),a._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v(" Scalable, efficient analysis of Big Data\n")])])]),t("h2",{attrs:{id:"빅-데이터란"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#빅-데이터란"}},[a._v("#")]),a._v(" 빅 데이터란?")]),a._v(" "),t("ul",[t("li",[a._v("온라인에서의 정보 ( ex. 클릭지표, 네트워크 메세지, 광고 지표 등 )")]),a._v(" "),t("li",[a._v("유저에 의해 생성된 정보 ( ex. 페이스북, 인스타그램, 트위터 등 )")]),a._v(" "),t("li",[a._v("건강 및 과학 컴퓨팅")]),a._v(" "),t("li",[a._v("그래프 데이터 ( ex. Social networks, Road networks.. )")]),a._v(" "),t("li",[a._v("로그 파일 ( ex. 아파치 웹 서버 로그.. )")]),a._v(" "),t("li",[a._v("Machine Syslog File")])]),a._v(" "),t("h3",{attrs:{id:"주요-데이터-컨셉"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#주요-데이터-컨셉"}},[a._v("#")]),a._v(" 주요 데이터 컨셉")]),a._v(" "),t("ul",[t("li",[t("em",[a._v("data model")]),a._v(" : 데이터를 이루는 컨셉들의 모음")]),a._v(" "),t("li",[t("em",[a._v("schema")]),a._v(" : data model 의 특정 모음을 나타내는 것")])]),a._v(" "),t("h2",{attrs:{id:"the-structure-spectrum"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#the-structure-spectrum"}},[a._v("#")]),a._v(" The Structure Spectrum")]),a._v(" "),t("p",[t("img",{attrs:{src:r(321),alt:""}}),a._v("\nETL : Extract-Transform-Load")]),a._v(" "),t("ul",[t("li",[a._v("Unstructured 데이터를 Structured 혹은 Semi-Structured 데이터로 변환.")])]),a._v(" "),t("h3",{attrs:{id:"옛날-분석-툴의-문제점"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#옛날-분석-툴의-문제점"}},[a._v("#")]),a._v(" 옛날 분석 툴의 문제점")]),a._v(" "),t("ul",[t("li",[a._v("모든 걸 다 한 머신에서! > 데이터가 점점 커진다  > 나눠서 처리하자\n"),t("img",{attrs:{src:r(322),alt:""}})])]),a._v(" "),t("p",[a._v("스파크 프레임 워크")]),a._v(" "),t("ul",[t("li",[a._v("Provides programming abstraction and parallel runtime to hide complexities of fault-tolerance and slow machines")])]),a._v(" "),t("h2",{attrs:{id:"스파크-컴포넌트-구성"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#스파크-컴포넌트-구성"}},[a._v("#")]),a._v(" 스파크 컴포넌트 구성")]),a._v(" "),t("p",[t("img",{attrs:{src:r(323),alt:""}}),a._v("\n이 강의에서는 SparkSQL을 사용하며 Python Spark ("),t("a",{attrs:{href:"http://spark.apache.org/docs/latest/api/python/",target:"_blank",rel:"noopener noreferrer"}},[a._v("pySpark"),t("OutboundLink")],1),a._v(")를 사용함.")]),a._v(" "),t("ul",[t("li",[a._v("pySpark provides an easy-to-use programming abstraction and parallel runtime:")])]),a._v(" "),t("h2",{attrs:{id:"spark-driver-와-workers"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-driver-와-workers"}},[a._v("#")]),a._v(" Spark Driver 와 Workers")]),a._v(" "),t("ul",[t("li",[a._v("(간단히) Driver Program이 시키면 Worker들이 일한다.\n"),t("img",{attrs:{src:r(324),alt:""}})])]),a._v(" "),t("h3",{attrs:{id:"sparkcontext"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sparkcontext"}},[a._v("#")]),a._v(" SparkContext")]),a._v(" "),t("ul",[t("li",[a._v("스파크가 어떻게 어디서 클러스터를 접근할 지 알려준다.")]),a._v(" "),t("li",[a._v("pySpark 나, Databricks CE에서는 자동으로 SparkContext를 생성")]),a._v(" "),t("li",[a._v("iPython이나 프로그램에서는 반드시 new SparkContext를 해주어야 한다.")])]),a._v(" "),t("p",[a._v("그리고 sqlContext 객체를 생성.\nsqlContext를 이용하여 DataFrames를 생성.")]),a._v(" "),t("h2",{attrs:{id:"dataframes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dataframes"}},[a._v("#")]),a._v(" DataFrames")]),a._v(" "),t("ul",[t("li",[a._v("불변 객체 (Immutable once constructed). 한번 생성되면 절때 불변!")]),a._v(" "),t("li",[a._v("parellel 하게 작동할수 있음.")]),a._v(" "),t("li",[a._v("Python collection(list) 를 사용할 수 있음")]),a._v(" "),t("li",[a._v("Spark나 pandas DFs를 DataFrame으로 바꿀 수 있음")]),a._v(" "),t("li",[a._v("HDFS에서 가져 올 수 있음.")]),a._v(" "),t("li",[a._v("각 로우는 Row 오브젝트임")])]),a._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("ex )\n>>> row = Row(name=“Cheese”, age=11)\n>>> row\nRow(age = 11, name=“Cheese”)\n>>> row[‘name’], row[‘age’]\n(‘Cheese’, 11)\n>>> row.name, row.age\n(‘Cheese’,11)\n")])])]),t("ul",[t("li",[a._v("두개의 타입의 작업이 가능 : "),t("em",[a._v("transformation")]),a._v(" 과 "),t("em",[a._v("action")]),a._v(" (기억하자!)")])]),a._v(" "),t("h3",{attrs:{id:"transformation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#transformation"}},[a._v("#")]),a._v(" Transformation")]),a._v(" "),t("ul",[t("li",[a._v("lazy (not computed immediately")]),a._v(" "),t("li",[a._v("transformed DF는 action이 run 되는 시점에 실행이 됨")]),a._v(" "),t("li",[a._v("Persist (cache) DF는 메모리 혹은 disk에 저장됨.\n"),t("img",{attrs:{src:r(325),alt:""}})])]),a._v(" "),t("h3",{attrs:{id:"action"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#action"}},[a._v("#")]),a._v(" Action")]),a._v(" "),t("p",[t("img",{attrs:{src:r(326),alt:""}})]),a._v(" "),t("h2",{attrs:{id:"스파크-프로그램의-life-cycle-정리"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#스파크-프로그램의-life-cycle-정리"}},[a._v("#")]),a._v(" 스파크 프로그램의 life cycle 정리")]),a._v(" "),t("ul",[t("li",[a._v("외부 데이터를 가져오거나 “createDataFrame” 을 통해 DF을 생성")]),a._v(" "),t("li",[a._v("-> transform 을 이용해 새로운 DataFrame에 lazy로")]),a._v(" "),t("li",[a._v("-> cache()를 이용하면 다시 사용 가능")]),a._v(" "),t("li",[a._v("-> action을 통해 parallel하게 실행되고 결과 값을 생성")])])])}),[],!1,null,null,null);t.default=s.exports}}]);